---
leaderboard: 263e7d41-65a5-4b7b-8f48-5c7b94ca916b
name: EB-Navigation
description: >
  EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents
organization: University of Illinois Urbana-Champaign, Northwestern University, University of Toronto, Toyota Technological Institute at Chicago
released:
  at:
    year: 2025
    month: 2
    date: null
Github: https://github.com/EmbodiedBench/EmbodiedBench
Hugging face: null
Project: https://embodiedbench.github.io/
default:
  property: TotalSR
properties:
  Base:
    order: 1
    index: 0
    label: Base
    unit: null
  Common:
    order: 2
    index: 1
    label: Common
    unit: null
  Complex:
    order: 3
    index: 2
    label: Complex
    unit: null
  Visual:
    order: 4
    index: 3
    label: Visual
    unit: null
  Long:
    order: 5
    index: 4
    label: Long
    unit: null
  TotalSR:
    order: 0
    index: 5
    label: Total SR
    unit: null
---

## Benchmark Introduction

![alt text](assets/1-1.png)

## Benchmark characteristics

## Benchmark Statistics

## Benchmark Evaluation

## Citation

```
@article{yang2025embodiedbench,
  title={EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents},
  author={Yang, Rui and Chen, Hanyang and Zhang, Junyu and Zhao, Mark and Qian, Cheng and Wang, Kangrui and Wang, Qineng and Koripella, Teja Venkat and Movahedi, Marziyeh and Li, Manling and others},
  journal={arXiv preprint arXiv:2502.09560},
  year={2025}
}

```
