COMMENT: To advance embodied reasoning in Vision-Language Models (VLMs), ERQA
(Embodied Reasoning Question Answering) is introduced as a benchmark
specifically targeting capabilities essential for agents interacting with the
physical world. ERQA includes 400 multiple-choice Visual Question Answering
(VQA)-style questions spanning a diverse set of categories, such as spatial
reasoning, trajectory reasoning, action reasoning, state estimation,
pointing, multi-view reasoning, and task reasoning. Unlike existing VLM
benchmarks that primarily focus on atomic skills like object recognition,
counting, or localization, ERQA emphasizes higher-level reasoning skills
critical for physical interaction, making it a complementary addition to
current evaluation suites.
