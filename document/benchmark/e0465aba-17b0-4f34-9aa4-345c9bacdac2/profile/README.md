ScanQA is a benchmark designed to evaluate 3D spatial
understanding through the task of 3D question answering (3D-QA). In this
task, models are given full 3D representations of indoor scenes—captured as
rich RGB-D scans—and are required to answer free-form textual questions
grounded in the 3D environment. Unlike traditional 2D question answering
tasks, 3D-QA demands a deeper understanding of spatial relationships, object
locations, orientations, and contextual alignment within three-dimensional
space. ScanQA includes over 41,000 human-edited question-answer pairs
collected from 800 indoor scenes based on the ScanNet dataset. It poses
unique challenges in linking natural language to spatially grounded visual
information, offering a comprehensive benchmark for evaluating multimodal
reasoning in 3D environments.

Reference:  
Azuma D, Miyanishi T, Kurita S, et al. Scanqa: 3d question answering for spatial scene understanding[C]//proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022: 19129-19139.
