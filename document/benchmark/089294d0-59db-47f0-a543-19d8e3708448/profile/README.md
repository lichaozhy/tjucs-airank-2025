VABench, a challenging benchmark with 300 manually annotated problems from
real-world and simulation datasets (OXE, BridgeData, Droid). VABench evaluates
models' abilities to generate spatial affordance and visual traces from natural
language instructions, using metrics including point accuracy, trajectory
MAE/RMSE, and GPT-based qualitative scoring.

Reference:  
Yifu Yuan and Haiqin Cui and Yibin Chen and Zibin Dong and Fei Ni and Longxin Kou and Jinyi Liu and Pengyi Li and Yan Zheng and Jianye Hao: From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation, 2025
