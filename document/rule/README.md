# Embodied Arena Leaderboard Rules

The Embodied Arena Leaderboards select benchmarks with wide influence in the field of embodied intelligence, and evaluate influential models and academic frontier models at home and abroad to form the Leaderboards.

## 1.1 Benchmark Source
- Influential academic benchmarks:
  - Embodied Question Answering Benchmarks:
    - OpenEQA, VSI-Bench, ScanQA (3D), etc.
  - Embodied Navigation Benchmarks:
    - HM3D, MP3D, EB-Navigation, etc.
  - Embodied Task Planning Benchmarks:
    - ET-Plan-Bench, EB-Habitat, EB-ALFRED, etc.
## 1.2 Model Type
- Influential Models
  - GPT-4o, Gemini-2.5-Pro, Claude-3.5-Sonnet, Qwen-VL-Max, LLaVA-OneVision, InternVL3, VILA-1.5, etc.
- Academic frontier models
  - RoboBrain, RoboPoint, UniNavid, SpatialVLM, etc.
- Models willing to join (please write an email to ***@tju.edu.cn to apply to join the Leaderboards)
  - Please provide the weight link of Hugging Face or ModelScope.
  - Please provide the API URL link, and indicate the model version supporting the OpenAI protocol interface.
  (! Note: Please provide the key of the corresponding model to ***@tju.edu.cn)

## 1.3 Update Frequency

### Regular update mechanism
- The Leaderboards are updated once a month, and a snapshot of the results is taken on the first working day of each month, as the leaderboards of the previous month.

- Each manufacturer is only supported to submit an evaluation application once a month. After receiving the evaluation application, it is generally updated within 7 working days

## Contact us

- **Organizer**: Tianjin University Deep Reinforcement Learning Laboratory
- **Copyright Statement**: Â© 2025 Tianjin University All Rights Reserved
- **Technical Support**: Tianjin University Deep Reinforcement Learning Laboratory

---

**Embodied Arena** - A professional evaluation platform to promote the development of embodied intelligence technology